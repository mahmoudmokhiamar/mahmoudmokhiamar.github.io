---
layout: book-shelf
title: Papers/Research Articles
permalink: papers
nav: false
collection: books
---
> "The future depends on some graduate student who is deeply suspicious of everything I have said."
>
> — Geoffrey Hinton

## Research papers that I have read, am reading, or plan to dive into


- 🧬 **Attention Is All You Need** – Vaswani et al.  
  *(The groundbreaking paper that introduced the Transformer architecture.)*

- 🧠 **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding** – Devlin et al.  
  *(Revolutionized Natural Language Processing with contextual embeddings.)*

- 🧹 **Rethinking "Attention" in Explainable AI** – Abnar & Zuidema  
  *(Investigates how attention weights relate to model interpretability.)*

- 🧩 **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks** – Lewis et al.  
  *(Blends retrieval and generation to enhance factual answering.)*

- 🏥 **Explainable Deep Learning Models for Medical Diagnosis** – Holzinger et al.  
  *(Focused on transparency and trust in AI-assisted healthcare.)*

  

---